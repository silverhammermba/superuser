---
layout: chapter
title: 'Security'
category: part2
---

Get ready. This chapter is probably the most important chapter in the book. It's
also one of the trickiest. We're going to talk about security as it applies to
information and computers.

## Definition ##

What does it really mean to be "secure"?

**Security** is the... hmm. Well... I can't think of any short way of saying
this.
{: .definition}

I'm sure that most people desire and appreciate security, but outside of a gut
instinct I doubt that the average Joe could tell you exactly what is or is not
secure - especially when it comes to computer stuff. Part of this difficulty
comes from Security being quite an overloaded term.

If something is "secure", we often think of it as "safe" - but safe in what way?

### Confidentiality ###

It could be safe from prying eyes.

Confidentiality is about keeping information secret. This is the type of
security that I think most people have in mind when they think about computers.
Confidentiality is especially important with the Internet since every message
must pass through several intermediate computers before reaching the recipient.

### Integrity ###

It could be safe from damage or modification.

Integrity is about ensuring that information cannot be secretly modified or
modified without authorization. Integrity can be just as important as
confidentiality.

Suppose you make a confidential credit card purchase - so no one can steal your
credit card information - but the purchase lacks integrity. A third party might
not be able to read your credit card number but they could substitute a
different one. Since the transaction does not have integrity, the store you
purchased from would be unaware of the change and would charge the wrong
person or refuse the transaction.

### Availability ###

It could be safe from disruption.

What use is information if it isn't available when you need it? If a hacker were
able to shut down your bank's computer systems, it would still be a big problem
for you even if none of your money or information was stolen.

### Non-Repudiation ###

It could be safe from deniability.

Unlike the other components of security, non-repudiation concerns the people who
are _supposed_ to have access to the information. It means that the parties
involved cannot later deny their involvement.

For example, after making a credit card purchase you could attempt to claim that
you did not authorize the purchase and should be refunded. Alternatively, the
store could claim that they never received the money and so you must make the
payment again. Non-repudiation seeks to prevent both kinds of situtations.

## Ciphers ##

While those principles are good for conceptually thinking about security, we
need a way to implement them for computers. That is largely done with a single
versatile tool: ciphers.

A cipher is basically another [format][fm] for encoding information. Back when
we first started learning about [the Internet][int], I compared the act of
formatting data into a packet to putting a letter into a package. Ciphers are
similar, but the package is a metal safe with a lock on it. To open it you need
a little something extra: a key. In real life that key could be numbers for a
combination lock or a physical key for a padlock, but with a cipher it's just
extra information.

[fm]: {% post_url 2011-04-06-ch4 %}
[int]: {% post_url 2012-01-01-ch1 %}/#packaging

A **cipher** is a data format that can only be decoded using additional
(usually secret) information called a key. Ciphers are often called **codes**
by the general public, but this can be confusing to a superuser since "code" has
several other technical meanings.
{: .definition}

Ciphers might just be a different type of data format, but there are lots of
cool and fancy words for talking about them.

**Plaintext** is just regular information that will be used with a cipher. The
"text" part is a misnomer since most ciphers can store any sort of information:
text, image, audio, video, etc.
{: .definition}

**Ciphertext** is the result of using a cipher with plaintext. This is the
padlocked safe.
{: .definition}

**Encryption** is the process of producing ciphertext from plaintext. The
reverse process of getting the plaintext back from the ciphertext (usually using
the key) is **decryption**. Ciphertext is often referred to as **encrypted**
information.
{: .definition}

While cipher and ciphertext are proper terms for discussing this topic, you
won't hear them very much among regular folk. They are mostly used by those who
study ciphers professionally.
{: .note}

## Hail Caesar ##

Caesar's cipher is a classic example from the BC years. It was used extensively
by Julius Caesar himself to relay battle orders. It is very simple to use even
without a computer. First you choose a key, which can be any number.  We'll pick 5.
Then you take your message

    ATTACK AT DAWN

and encrypt it by replacing each letter with the 5th letter after it in the
alphabet, wrapping around from Z back to A if necessary. For example A becomes
F, D becomes I, X becomes C, etc. This gives us the ciphertext

    FYYFHP FY IFBS

There's our confidentiality! If our foes intercept our message they will have no
idea what is actually being said. But since the true recipient of our message
knows that we're using the Caesar cipher with a key of 5, they can decrypt the
message by shifting the letters in the opposite direction by that amount.

Note that we also get a bit of information integrity for free. Someone could try
to intercept our message and add false information to it, but without knowing
the key there is little chance that what they add would make sense once the
message is decrypted.

## Cryptanalysis ##

But Caesar's cipher - as you might expect for something over 2,000 years old -
isn't very strong. Consider the fact that using a key of 26 is the same as using
a key of 0 i.e. nothing gets shifted and your ciphertext would be identical to
your plaintext. Similarly using a key of 27 is the same as a key of 1, using 28
is the same as 2, etc. In other words, there are really only 26 different key
values and one of them (0) is useless since it does nothing at all. Why is this
a problem?

Well, suppose our foes _do_ intercept our ciphertext. If they know that we're
fond of the Caesar cipher, they can guess that we probably didn't use the key 0
so they try the other 25 keys:

    EXXEGO EX HEAR
    DWWDFN DW GDZQ
    CVVCEM CV FCYP
    BUUBDL BU EBXO
    ATTACK AT DAWN
    ...
    IBBIKS IB LIEV
    HAAHJR HA KHDU
    GZZGIQ GZ JGCT

The key guess of 1 produces a pretty compelling "EXXEGO EX HEAR", but I think
they might pick out "ATTACK AT DAWN" which - unlike every other key guess -
produces three actual English words. If the message were longer, the
interceptors could be even more confident of their guess since it would be even
less likely that the wrong key would produce a legible phrase. The interceptors
now have our plaintext _and_ the key.

**Cryptanalysis** is the study of ciphers, often for the purpose of extracting
the key or plaintext from ciphertext.
{: .definition}

With the key in hand, the interceptors have completely compromised the security
of our cipher. They can read the message or even change it to "FYYFHP FY STTS"
to ruin our battle plan. Is there a better form of encryption?

## One-Time Pad ##

It turns out that there is. In fact there is a _perfect_ cipher - one that is
completely unbreakable. The key, however, needs to be much larger.  Rather than
picking just one number, now we pick a random number for _every letter_ in our
plaintext. "ATTACK AT DAWN" has 12 letters, so after a little work with a
26-sided die, we get

    6 4 5 5 9 12 6 1 0 16 16 0

Note that while a key of zero was useless for the Caesar cipher, now zeros in
our key are okay!
{: .note}

Encryption is similar to the Caesar cipher but now each letter is shifted by its
corresponding number in the key. The first A is shifted 6 to become G, the first
T shifts 4 to become X, the next T shifts 5 to become Y, and so on. The result
is

    GXYFLW GU DQMN

Why is this suddenly unbreakable? After all, our adversaries can once again try
every key as they did before. Well their first challenge is that there are now
26<sup>12</sup> = 95,428,956,661,682,176 keys to try. Trying that many keys
would be time-consuming even for a computer, but even ignoring the practical
details there is a much more problematic obstacle. Suppose our adversaries guess

    key: 8 1 0 20 10 17 0 19 16 0 15 2
    plaintext: YWYLBF GB NQXL

This is clearly gibberish, so the key is probably wrong. They try some more keys
and eventually get

    key: 6 4 5 5 9 12 6 1 0 16 16 0
    plaintext: ATTACK AT DAWN

Ah ha! This looks legitimate! But then they keep going and get

    key: 6 4 5 5 9 12 6 1 16 2 24 0
    plaintext: ATTACK AT NOON

or is it

    key: 6 4 5 5 9 12 20 22 18 16 16 0
    plaintext: ATTACK MY LAWN

and we really can't rule out

    key: 1 9 11 2 0 18 20 22 2 22 19 20
    plaintext: FONDLE MY BUTT

The point is that there is now a key for _every possible combination of letters_
- that includes every single grammatically correct English sentence with three
words of those lengths. There is no way for our adversaries to know which phrase
we meant!

This type of encryption has some downsides, however. For one, you need a whole
lot of key. Suppose you wanted to encrypt an entire book - that would require an
awful lot of dice rolling! And even if you had that much key, you would need to
somehow secretly get the key to the recipient ahead of time without it being
intercepted. Lastly, the security of the cipher relies on the fact that you
never reuse a key. So even if you go through all of that effort to generate a
lot of key and get it to the recipient secretly, after one message you have to
throw it out.

<div class="deeper">
As for _why_ one should not reuse key with this cipher... that's a little
tricky.

Suppose you sent a long message each day with this cipher but reused the same
key each time. A patient adversary could collect all of your messages and
compare them. If they figure out that you're using the same key each day, then
they know that the first letter of each message is shifted by the same amount.
If any of your messages start with a one-letter word, then your adversaries
would immediately know that the shift needs to be something to give a plaintext
of A or I in those messages (since these are the only common one-letter words).
Using those two shifts, they can guess the first letters of the messages
starting with two-letter words. Since there are only so many two-letter words,
this helps them guess the shift for the second letter in the message. And so on.

The crucial difference is this: with only one random key and one plaintext,
correctly guessing _part_ of the key gives you no insight to the rest of the key
(see "ATTACK MY LAWN"). When you reuse key across multiple messages, it creates
patterns among the ciphertext that a clever adversary could detect.
</div>

Because of these limitations, before the age of computers this cipher was
implemented using mass-produced pads of paper with sheet after sheet of random
numbers on them. For example, the pads would be distributed to naval vessels
before a long voyage with instructions about which page of the pad was to be
used for key each day. This allowed for secure communication so long as the
pads never fell into enemy hands. For this reason many pads were designed to
quickly dissolve in water, so that they would not be recoverable if the vessel
were to sink. Even when used today in digital communications, this cipher is
often referred to as a one-time pad.

## Going Binary ##

When computers do encryption they follow very similar steps to those we just
learned about: take your plaintext, add key to it, get your ciphertext. But of
course now everything needs to be in binary.

Let's start with the simplest possible binary plaintext: a single bit. I pick 1.
Previously we had one number in our key for each letter in our plaintext, so in
binary there's only one sensible choice: we'll have one random _bit_ of key for
each bit of plaintext. Suppose our computer flips a coin and gets the random bit
1 for our key.

Now we have to add them together. Previously that meant shifting letters in the
alphabet, but again things are simpler now that it's all binary. We can add the
bits together mathematically.

    1 + 1 = ?

Now, in binary, that would normally be 10 but we're going to add in a weird sort
of way. To keep things simple we'll ignore the 1 that is carried over, leaving
just the 0. For the other possible values of binary addition we don't have to
carry a digit, so the addition occurs normally. To recap, here's all the cases
for this weird addition:

    0 + 0 = 0
    0 + 1 = 1
    1 + 0 = 1
    1 + 1 = 0

There are a few different names for this kind of addition. Sometimes it's called
"addition modulo 2" (or mod 2 addition), which means that we force the answer to
always be smaller than 2. It is also called "exclusive or" (or xor; pronounced
"exor") since A + B equals 1 if A is 1 **or** B is 1 **but not both**. You will
also see people distinguish it from regular addition by putting a circle around
the plus sign e.g. 1 ⊕ 1 = 0.

If you think way back to the chapter on [adding machines][sm], you might
recognize this as a sort of overflow. We have only one wheel with 0 and 1 on it,
so when adding 1 to 1 we loop back to 0 and there are no others wheels to pick
up the extra 1.
{: .deeper}

[sm]: {% post_url 2011-03-01-ch2 %}

Using xor, it's very easy to add even long binary numbers by hand since you
never have to keep track of carried digits. You can look at each pair of digits
on their own.

In our case, our plaintext is 1, our key is 1, so our ciphertext is 0. As
before, we have perfect secrecy using this method. Our random key could have
been 0 or 1, so our adversaries have no idea whether our plaintext was 0 or 1.
But how do we decrypt? Once again, this proves even easier than before. Note the
following:

    0 ⊕ 0 = 0
    1 ⊕ 1 = 0

    0 ⊕ 0 = 0
    1 ⊕ 0 = 1

In other words, for xor we have the two rules

    X ⊕ X = 0
    X ⊕ 0 = X

Now recall how encryption worked:

    plaintext ⊕ key = ciphertext

Therefore

    plaintext ⊕ key ⊕ key = ciphertext ⊕ key
    plaintext ⊕ (key ⊕ key) = ciphertext ⊕ key
    plaintext ⊕ 0 = ciphertext ⊕ key
    plaintext = ciphertext ⊕ key

The process for encryption is the _exact same_ as for decryption! Add key to plaintext
and you get ciphertext, add key to ciphertext and you get plaintext! Cool, huh?

Now perhaps you aren't impressed by any of this since all we encrypted was a
measely bit, but what is binary data other than a string of bits? All you need
is a binary format for your data and random bits of key for each of your
plaintext bits and you're good to go: encrypt each bit individually as we just
did. Using [ASCII][as] to encode "ATTACK" as binary, and using 48 random bits of
key, we can encrypt text:

[as]: {% post_url 2012-03-01-ch3 %}#text

       01000001 01010100 01010100 01000001 01000011 01001011 (plaintext)
     ⊕ 01000000 11101110 11100111 11110101 01101110 00000011 (key)
    --------------------------------------------------------
       00000001 10111010 10110011 10110100 00101101 01001000 (ciphertext)

## Cheating ##

Now that we know how to do perfect encryption in binary, what more could there
be to discuss? It turns out that there's a lot, because one-time pads are
extremely impractical when it comes digital encryption. Remember that you need
just as much key as plaintext, and to maintain security of the one-time pad you
cannot ever reuse key. Computers regularly encrypt megabytes if not gigabytes of
information, meaning that you'll need millions or billions of random bits every
day. Why is that a problem? Recall that computers are machines that compute
functions: algorithms that give you the same result every time you provide the
same input. That is exactly what we _don't_ want when it comes to randomness! We
want the computer to be able to generate different key bits every time it
encrypts.

Luckily, engineers have found a few tricks for getting random numbers out of
computers - such as timing user input or reading information from the various
devices plugged into the computer. However these methods are very slow compared
to normal computation. For example, on the laptop I'm writing this with, my
computer can only generate about 3-4 bytes of randomness per second during
normal use. If I stop using it, it quickly runs out of randomness since I've
deprived it of a major source of randomness (my input). One way computers get
around this limitation is that they're _always_ generating randomness, and if
you don't need it at that moment, they save it for later in something called an
entropy pool.

Randomness is sometimes referred to as **entropy** - especially when it comes to
measuring randomness. For example, suppose we generate 16 random bits using an
unfair coin that lands on heads 70% of the time. The result will still be
"random", but using some [fancy math][coin] we can determine that it has only 14
bits of entropy. In other words, it has the same "amount" of randomness as 14
bits produced by a completely fair coin.
{: .definition}

[coin]: http://www.eecs.harvard.edu/~michaelm/coinflipext.pdf


